{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import uisrnn\n",
    "\n",
    "SAVED_MODEL_NAME = 'demo_model.uisrnn'\n",
    "\n",
    "def diarization_experiment(model_args, training_args, inference_args):\n",
    "    \"\"\"Experiment pipeline.\n",
    "\n",
    "    Load data --> train model --> test model --> output result\n",
    "\n",
    "    Args:\n",
    "    model_args: model configurations\n",
    "    training_args: training configurations\n",
    "    inference_args: inference configurations\n",
    "    \"\"\"\n",
    "\n",
    "    predicted_cluster_ids = []\n",
    "    test_record = []\n",
    "\n",
    "    train_data = np.load('../data/uisrnn/toy_training_data.npz', allow_pickle=True)\n",
    "    test_data = np.load('../data/uisrnn/toy_testing_data.npz', allow_pickle=True)\n",
    "    train_sequence = train_data['train_sequence']\n",
    "    train_cluster_id = train_data['train_cluster_id']\n",
    "    test_sequences = test_data['test_sequences'].tolist()\n",
    "    test_cluster_ids = test_data['test_cluster_ids'].tolist()\n",
    "\n",
    "    model = uisrnn.UISRNN(model_args)\n",
    "\n",
    "    # Training.\n",
    "    # If we have saved a mode previously, we can also skip training by\n",
    "    # callingï¼š\n",
    "    # model.load(SAVED_MODEL_NAME)\n",
    "    model.fit(train_sequence, train_cluster_id, training_args)\n",
    "    model.save(SAVED_MODEL_NAME)\n",
    "\n",
    "    # Testing.\n",
    "    # You can also try uisrnn.parallel_predict to speed up with GPU.\n",
    "    # But that is a beta feature which is not thoroughly tested, so\n",
    "    # proceed with caution.\n",
    "    for (test_sequence, test_cluster_id) in zip(test_sequences, test_cluster_ids):\n",
    "        predicted_cluster_id = model.predict(test_sequence, inference_args)\n",
    "        predicted_cluster_ids.append(predicted_cluster_id)\n",
    "        accuracy = uisrnn.compute_sequence_match_accuracy(\n",
    "            test_cluster_id, predicted_cluster_id)\n",
    "        test_record.append((accuracy, len(test_cluster_id)))\n",
    "        print('Ground truth labels:')\n",
    "        print(test_cluster_id)\n",
    "        print('Predicted labels:')\n",
    "        print(predicted_cluster_id)\n",
    "        print('-' * 80)\n",
    "\n",
    "    output_string = uisrnn.output_result(model_args, training_args, test_record)\n",
    "\n",
    "    print('Finished diarization experiment')\n",
    "    print(output_string)\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"The main function.\"\"\"\n",
    "    model_args, training_args, inference_args = parse_arguments()\n",
    "    diarization_experiment(model_args, training_args, inference_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import easydict\n",
    "\n",
    "def parse_arguments():\n",
    "    model_args = easydict.EasyDict({\n",
    "        \"observation_dim\": 256,\n",
    "        \"rnn_hidden_size\": 512,\n",
    "        \"rnn_depth\": 1,\n",
    "        \"rnn_dropout\": 0.2,\n",
    "        \"transition_bias\": None,\n",
    "        \"crp_alpha\": 1.0,\n",
    "        \"sigma2\": None,\n",
    "        \"verbosity\": 2,\n",
    "        \"enable_cuda\": True,\n",
    "    })\n",
    "    training_args = easydict.EasyDict({\n",
    "        \"optimizer\": 'adam',\n",
    "        \"learning_rate\": 1e-3,\n",
    "        \"train_iteration\": 1000,\n",
    "        \"batch_size\": 10,\n",
    "        \"num_permutations\": 10,\n",
    "        \"sigma_alpha\": 1.0,\n",
    "        \"sigma_beta\": 1.0,\n",
    "        \"regularization_weight\": 1e-5,\n",
    "        \"grad_max_norm\": 5.0,\n",
    "        \"enforce_cluster_id_uniqueness\": True,\n",
    "    })\n",
    "    inference_args = easydict.EasyDict({\n",
    "        \"beam_size\": 10,\n",
    "        \"look_ahead\": 1,\n",
    "        \"test_iteration\": 2,\n",
    "    })\n",
    "\n",
    "    return (model_args, training_args, inference_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: transition_bias cannot be correctly estimated from a concatenated sequence; train_sequences will be treated as a single sequence. This can lead to inaccurate estimation of transition_bias. Please, consider estimating transition_bias before concatenating the sequences and passing it as argument.\n",
      "Iter: 0  \tTraining Loss: -284.1512    \n",
      "    Negative Log Likelihood: 6.0657\tSigma2 Prior: -290.2176\tRegularization: 0.0006\n",
      "Iter: 10  \tTraining Loss: -299.1838    \n",
      "    Negative Log Likelihood: 5.6170\tSigma2 Prior: -304.8014\tRegularization: 0.0006\n",
      "Iter: 20  \tTraining Loss: -312.5705    \n",
      "    Negative Log Likelihood: 6.2607\tSigma2 Prior: -318.8318\tRegularization: 0.0006\n",
      "Iter: 30  \tTraining Loss: -331.4164    \n",
      "    Negative Log Likelihood: 7.0363\tSigma2 Prior: -338.4533\tRegularization: 0.0006\n",
      "Iter: 40  \tTraining Loss: -347.3345    \n",
      "    Negative Log Likelihood: 8.4671\tSigma2 Prior: -355.8022\tRegularization: 0.0006\n",
      "Iter: 50  \tTraining Loss: -367.5362    \n",
      "    Negative Log Likelihood: 10.4008\tSigma2 Prior: -377.9376\tRegularization: 0.0007\n",
      "Iter: 60  \tTraining Loss: -401.8967    \n",
      "    Negative Log Likelihood: 14.0404\tSigma2 Prior: -415.9377\tRegularization: 0.0007\n",
      "Iter: 70  \tTraining Loss: -445.7974    \n",
      "    Negative Log Likelihood: 22.8770\tSigma2 Prior: -468.6751\tRegularization: 0.0007\n",
      "Iter: 80  \tTraining Loss: -488.4991    \n",
      "    Negative Log Likelihood: 63.3888\tSigma2 Prior: -551.8885\tRegularization: 0.0007\n",
      "Iter: 90  \tTraining Loss: -486.9724    \n",
      "    Negative Log Likelihood: 38.9569\tSigma2 Prior: -525.9301\tRegularization: 0.0007\n",
      "Iter: 100  \tTraining Loss: -464.2897    \n",
      "    Negative Log Likelihood: 40.7182\tSigma2 Prior: -505.0086\tRegularization: 0.0007\n",
      "Iter: 110  \tTraining Loss: -471.2397    \n",
      "    Negative Log Likelihood: 48.9915\tSigma2 Prior: -520.2319\tRegularization: 0.0007\n",
      "Iter: 120  \tTraining Loss: -478.5259    \n",
      "    Negative Log Likelihood: 48.6561\tSigma2 Prior: -527.1827\tRegularization: 0.0007\n",
      "Iter: 130  \tTraining Loss: -491.8414    \n",
      "    Negative Log Likelihood: 41.7941\tSigma2 Prior: -533.6362\tRegularization: 0.0008\n",
      "Iter: 140  \tTraining Loss: -489.2370    \n",
      "    Negative Log Likelihood: 44.3042\tSigma2 Prior: -533.5420\tRegularization: 0.0008\n",
      "Iter: 150  \tTraining Loss: -511.9062    \n",
      "    Negative Log Likelihood: 43.7546\tSigma2 Prior: -555.6617\tRegularization: 0.0008\n",
      "Iter: 160  \tTraining Loss: -468.5919    \n",
      "    Negative Log Likelihood: 42.8701\tSigma2 Prior: -511.4627\tRegularization: 0.0008\n",
      "Iter: 170  \tTraining Loss: -472.1561    \n",
      "    Negative Log Likelihood: 43.2107\tSigma2 Prior: -515.3676\tRegularization: 0.0008\n",
      "Iter: 180  \tTraining Loss: -481.3011    \n",
      "    Negative Log Likelihood: 45.7376\tSigma2 Prior: -527.0396\tRegularization: 0.0008\n",
      "Iter: 190  \tTraining Loss: -464.6403    \n",
      "    Negative Log Likelihood: 42.6317\tSigma2 Prior: -507.2728\tRegularization: 0.0008\n",
      "Iter: 200  \tTraining Loss: -496.1435    \n",
      "    Negative Log Likelihood: 45.6042\tSigma2 Prior: -541.7485\tRegularization: 0.0009\n",
      "Iter: 210  \tTraining Loss: -488.7245    \n",
      "    Negative Log Likelihood: 45.2111\tSigma2 Prior: -533.9365\tRegularization: 0.0009\n",
      "Iter: 220  \tTraining Loss: -441.9322    \n",
      "    Negative Log Likelihood: 42.5921\tSigma2 Prior: -484.5251\tRegularization: 0.0009\n",
      "Iter: 230  \tTraining Loss: -479.6148    \n",
      "    Negative Log Likelihood: 43.4513\tSigma2 Prior: -523.0670\tRegularization: 0.0009\n",
      "Iter: 240  \tTraining Loss: -457.4526    \n",
      "    Negative Log Likelihood: 42.4300\tSigma2 Prior: -499.8835\tRegularization: 0.0009\n",
      "Iter: 250  \tTraining Loss: -498.2827    \n",
      "    Negative Log Likelihood: 39.1462\tSigma2 Prior: -537.4297\tRegularization: 0.0009\n",
      "Iter: 260  \tTraining Loss: -456.9839    \n",
      "    Negative Log Likelihood: 41.8032\tSigma2 Prior: -498.7881\tRegularization: 0.0010\n",
      "Iter: 270  \tTraining Loss: -498.3426    \n",
      "    Negative Log Likelihood: 39.6815\tSigma2 Prior: -538.0250\tRegularization: 0.0010\n",
      "Iter: 280  \tTraining Loss: -402.8456    \n",
      "    Negative Log Likelihood: 44.4329\tSigma2 Prior: -447.2794\tRegularization: 0.0010\n",
      "Iter: 290  \tTraining Loss: -480.4333    \n",
      "    Negative Log Likelihood: 32.6349\tSigma2 Prior: -513.0692\tRegularization: 0.0010\n",
      "Iter: 300  \tTraining Loss: -511.2595    \n",
      "    Negative Log Likelihood: 45.2207\tSigma2 Prior: -556.4812\tRegularization: 0.0010\n",
      "Iter: 310  \tTraining Loss: -489.6146    \n",
      "    Negative Log Likelihood: 37.6507\tSigma2 Prior: -527.2664\tRegularization: 0.0010\n",
      "Iter: 320  \tTraining Loss: -494.4796    \n",
      "    Negative Log Likelihood: 32.8765\tSigma2 Prior: -527.3571\tRegularization: 0.0010\n",
      "Iter: 330  \tTraining Loss: -461.8771    \n",
      "    Negative Log Likelihood: 44.0872\tSigma2 Prior: -505.9654\tRegularization: 0.0011\n",
      "Iter: 340  \tTraining Loss: -505.5758    \n",
      "    Negative Log Likelihood: 38.2822\tSigma2 Prior: -543.8591\tRegularization: 0.0011\n",
      "Iter: 350  \tTraining Loss: -496.1374    \n",
      "    Negative Log Likelihood: 36.6201\tSigma2 Prior: -532.7586\tRegularization: 0.0011\n",
      "Iter: 360  \tTraining Loss: -500.8478    \n",
      "    Negative Log Likelihood: 40.8035\tSigma2 Prior: -541.6524\tRegularization: 0.0011\n",
      "Iter: 370  \tTraining Loss: -482.4389    \n",
      "    Negative Log Likelihood: 38.7622\tSigma2 Prior: -521.2022\tRegularization: 0.0011\n",
      "Iter: 380  \tTraining Loss: -497.7509    \n",
      "    Negative Log Likelihood: 34.9735\tSigma2 Prior: -532.7255\tRegularization: 0.0011\n",
      "Iter: 390  \tTraining Loss: -500.8652    \n",
      "    Negative Log Likelihood: 39.6191\tSigma2 Prior: -540.4854\tRegularization: 0.0011\n",
      "Iter: 400  \tTraining Loss: -490.4207    \n",
      "    Negative Log Likelihood: 37.4228\tSigma2 Prior: -527.8447\tRegularization: 0.0011\n",
      "Iter: 410  \tTraining Loss: -476.4526    \n",
      "    Negative Log Likelihood: 35.0805\tSigma2 Prior: -511.5343\tRegularization: 0.0012\n",
      "Iter: 420  \tTraining Loss: -493.2003    \n",
      "    Negative Log Likelihood: 40.7341\tSigma2 Prior: -533.9355\tRegularization: 0.0012\n",
      "Iter: 430  \tTraining Loss: -484.5470    \n",
      "    Negative Log Likelihood: 38.2736\tSigma2 Prior: -522.8218\tRegularization: 0.0012\n",
      "Iter: 440  \tTraining Loss: -478.6312    \n",
      "    Negative Log Likelihood: 37.6304\tSigma2 Prior: -516.2627\tRegularization: 0.0012\n",
      "Iter: 450  \tTraining Loss: -500.8305    \n",
      "    Negative Log Likelihood: 38.4125\tSigma2 Prior: -539.2442\tRegularization: 0.0012\n",
      "Iter: 460  \tTraining Loss: -490.0247    \n",
      "    Negative Log Likelihood: 41.5057\tSigma2 Prior: -531.5316\tRegularization: 0.0012\n",
      "Iter: 470  \tTraining Loss: -490.6502    \n",
      "    Negative Log Likelihood: 36.5217\tSigma2 Prior: -527.1731\tRegularization: 0.0012\n",
      "Iter: 480  \tTraining Loss: -505.0683    \n",
      "    Negative Log Likelihood: 37.7936\tSigma2 Prior: -542.8632\tRegularization: 0.0012\n",
      "Iter: 490  \tTraining Loss: -467.3037    \n",
      "    Negative Log Likelihood: 41.6916\tSigma2 Prior: -508.9966\tRegularization: 0.0012\n",
      "Iter: 500  \tTraining Loss: -479.4073    \n",
      "    Negative Log Likelihood: 39.1334\tSigma2 Prior: -518.5420\tRegularization: 0.0012\n",
      "Iter: 510  \tTraining Loss: -458.5981    \n",
      "    Negative Log Likelihood: 35.4610\tSigma2 Prior: -494.0604\tRegularization: 0.0012\n",
      "Iter: 520  \tTraining Loss: -476.3421    \n",
      "    Negative Log Likelihood: 38.1462\tSigma2 Prior: -514.4895\tRegularization: 0.0012\n",
      "Iter: 530  \tTraining Loss: -478.9337    \n",
      "    Negative Log Likelihood: 40.1570\tSigma2 Prior: -519.0920\tRegularization: 0.0012\n",
      "Iter: 540  \tTraining Loss: -485.3292    \n",
      "    Negative Log Likelihood: 36.5197\tSigma2 Prior: -521.8502\tRegularization: 0.0012\n",
      "Iter: 550  \tTraining Loss: -499.3396    \n",
      "    Negative Log Likelihood: 40.1970\tSigma2 Prior: -539.5378\tRegularization: 0.0013\n",
      "Iter: 560  \tTraining Loss: -475.1410    \n",
      "    Negative Log Likelihood: 38.4059\tSigma2 Prior: -513.5482\tRegularization: 0.0013\n",
      "Iter: 570  \tTraining Loss: -485.3163    \n",
      "    Negative Log Likelihood: 39.1974\tSigma2 Prior: -524.5150\tRegularization: 0.0013\n",
      "Iter: 580  \tTraining Loss: -493.5211    \n",
      "    Negative Log Likelihood: 35.0989\tSigma2 Prior: -528.6212\tRegularization: 0.0013\n",
      "Iter: 590  \tTraining Loss: -487.5051    \n",
      "    Negative Log Likelihood: 35.5734\tSigma2 Prior: -523.0798\tRegularization: 0.0013\n",
      "Iter: 600  \tTraining Loss: -494.4458    \n",
      "    Negative Log Likelihood: 43.3815\tSigma2 Prior: -537.8286\tRegularization: 0.0013\n",
      "Iter: 610  \tTraining Loss: -502.9119    \n",
      "    Negative Log Likelihood: 37.2125\tSigma2 Prior: -540.1257\tRegularization: 0.0013\n",
      "Iter: 620  \tTraining Loss: -474.4867    \n",
      "    Negative Log Likelihood: 38.6351\tSigma2 Prior: -513.1230\tRegularization: 0.0013\n",
      "Iter: 630  \tTraining Loss: -481.2660    \n",
      "    Negative Log Likelihood: 34.1513\tSigma2 Prior: -515.4186\tRegularization: 0.0013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 640  \tTraining Loss: -459.2185    \n",
      "    Negative Log Likelihood: 44.9334\tSigma2 Prior: -504.1533\tRegularization: 0.0013\n",
      "Iter: 650  \tTraining Loss: -494.8901    \n",
      "    Negative Log Likelihood: 35.1457\tSigma2 Prior: -530.0371\tRegularization: 0.0013\n",
      "Iter: 660  \tTraining Loss: -480.8114    \n",
      "    Negative Log Likelihood: 39.9788\tSigma2 Prior: -520.7915\tRegularization: 0.0013\n",
      "Iter: 670  \tTraining Loss: -511.3131    \n",
      "    Negative Log Likelihood: 36.9350\tSigma2 Prior: -548.2495\tRegularization: 0.0013\n",
      "Iter: 680  \tTraining Loss: -461.6263    \n",
      "    Negative Log Likelihood: 42.8624\tSigma2 Prior: -504.4901\tRegularization: 0.0013\n",
      "Iter: 690  \tTraining Loss: -475.2091    \n",
      "    Negative Log Likelihood: 33.4636\tSigma2 Prior: -508.6740\tRegularization: 0.0013\n",
      "Iter: 700  \tTraining Loss: -504.2809    \n",
      "    Negative Log Likelihood: 36.6231\tSigma2 Prior: -540.9053\tRegularization: 0.0013\n",
      "Iter: 710  \tTraining Loss: -482.2141    \n",
      "    Negative Log Likelihood: 46.8791\tSigma2 Prior: -529.0946\tRegularization: 0.0013\n",
      "Iter: 720  \tTraining Loss: -479.4685    \n",
      "    Negative Log Likelihood: 33.8982\tSigma2 Prior: -513.3680\tRegularization: 0.0013\n",
      "Iter: 730  \tTraining Loss: -484.2553    \n",
      "    Negative Log Likelihood: 38.6850\tSigma2 Prior: -522.9417\tRegularization: 0.0014\n",
      "Iter: 740  \tTraining Loss: -484.3294    \n",
      "    Negative Log Likelihood: 36.3615\tSigma2 Prior: -520.6922\tRegularization: 0.0014\n",
      "Iter: 750  \tTraining Loss: -491.2938    \n",
      "    Negative Log Likelihood: 41.6621\tSigma2 Prior: -532.9573\tRegularization: 0.0014\n",
      "Iter: 760  \tTraining Loss: -497.3738    \n",
      "    Negative Log Likelihood: 40.7879\tSigma2 Prior: -538.1631\tRegularization: 0.0014\n",
      "Iter: 770  \tTraining Loss: -500.3526    \n",
      "    Negative Log Likelihood: 37.1227\tSigma2 Prior: -537.4767\tRegularization: 0.0014\n",
      "Iter: 780  \tTraining Loss: -426.3907    \n",
      "    Negative Log Likelihood: 42.6871\tSigma2 Prior: -469.0792\tRegularization: 0.0014\n",
      "Iter: 790  \tTraining Loss: -489.7162    \n",
      "    Negative Log Likelihood: 32.7323\tSigma2 Prior: -522.4498\tRegularization: 0.0014\n",
      "Iter: 800  \tTraining Loss: -503.7414    \n",
      "    Negative Log Likelihood: 35.8621\tSigma2 Prior: -539.6049\tRegularization: 0.0014\n",
      "Iter: 810  \tTraining Loss: -456.6861    \n",
      "    Negative Log Likelihood: 39.8038\tSigma2 Prior: -496.4913\tRegularization: 0.0014\n",
      "Iter: 820  \tTraining Loss: -485.5232    \n",
      "    Negative Log Likelihood: 36.3026\tSigma2 Prior: -521.8273\tRegularization: 0.0014\n",
      "Iter: 830  \tTraining Loss: -473.2755    \n",
      "    Negative Log Likelihood: 40.3133\tSigma2 Prior: -513.5902\tRegularization: 0.0014\n",
      "Iter: 840  \tTraining Loss: -461.7607    \n",
      "    Negative Log Likelihood: 39.2914\tSigma2 Prior: -501.0536\tRegularization: 0.0014\n",
      "Iter: 850  \tTraining Loss: -477.0755    \n",
      "    Negative Log Likelihood: 35.6799\tSigma2 Prior: -512.7568\tRegularization: 0.0014\n",
      "Iter: 860  \tTraining Loss: -491.3430    \n",
      "    Negative Log Likelihood: 39.5203\tSigma2 Prior: -530.8647\tRegularization: 0.0014\n",
      "Iter: 870  \tTraining Loss: -513.3650    \n",
      "    Negative Log Likelihood: 34.2358\tSigma2 Prior: -547.6022\tRegularization: 0.0014\n",
      "Iter: 880  \tTraining Loss: -523.0717    \n",
      "    Negative Log Likelihood: 39.0313\tSigma2 Prior: -562.1045\tRegularization: 0.0014\n",
      "Iter: 890  \tTraining Loss: -502.5994    \n",
      "    Negative Log Likelihood: 33.6576\tSigma2 Prior: -536.2584\tRegularization: 0.0014\n",
      "Iter: 900  \tTraining Loss: -492.8234    \n",
      "    Negative Log Likelihood: 39.7016\tSigma2 Prior: -532.5265\tRegularization: 0.0014\n",
      "Iter: 910  \tTraining Loss: -499.7661    \n",
      "    Negative Log Likelihood: 29.2237\tSigma2 Prior: -528.9912\tRegularization: 0.0014\n",
      "Iter: 920  \tTraining Loss: -464.1016    \n",
      "    Negative Log Likelihood: 36.4472\tSigma2 Prior: -500.5503\tRegularization: 0.0014\n",
      "Iter: 930  \tTraining Loss: -488.5889    \n",
      "    Negative Log Likelihood: 39.0462\tSigma2 Prior: -527.6365\tRegularization: 0.0014\n",
      "Iter: 940  \tTraining Loss: -480.7217    \n",
      "    Negative Log Likelihood: 42.6854\tSigma2 Prior: -523.4085\tRegularization: 0.0014\n",
      "Iter: 950  \tTraining Loss: -446.1714    \n",
      "    Negative Log Likelihood: 35.6530\tSigma2 Prior: -481.8258\tRegularization: 0.0015\n",
      "Iter: 960  \tTraining Loss: -452.7420    \n",
      "    Negative Log Likelihood: 38.7084\tSigma2 Prior: -491.4519\tRegularization: 0.0015\n",
      "Iter: 970  \tTraining Loss: -440.5370    \n",
      "    Negative Log Likelihood: 32.1061\tSigma2 Prior: -472.6445\tRegularization: 0.0015\n",
      "Iter: 980  \tTraining Loss: -482.7367    \n",
      "    Negative Log Likelihood: 36.3128\tSigma2 Prior: -519.0510\tRegularization: 0.0015\n",
      "Iter: 990  \tTraining Loss: -493.9293    \n",
      "    Negative Log Likelihood: 32.4029\tSigma2 Prior: -526.3337\tRegularization: 0.0015\n",
      "Iter: 999  \tTraining Loss: -493.3013    \n",
      "    Negative Log Likelihood: 33.8811\tSigma2 Prior: -527.1838\tRegularization: 0.0015\n",
      "Done training with 1000 iterations\n",
      "Ground truth labels:\n",
      "['15_0', '15_0', '15_0', '15_0', '15_0', '15_0', '15_0', '15_0', '15_1', '15_1', '15_1', '15_1', '15_1', '15_1', '15_1', '15_1', '15_1', '15_1', '15_1', '15_1', '15_1', '15_1', '15_1', '15_2', '15_2', '15_2', '15_2', '15_2', '15_2', '15_2', '15_2', '15_2', '15_2', '15_2', '15_2', '15_0', '15_0', '15_0', '15_0', '15_0', '15_1', '15_1', '15_1', '15_1', '15_1', '15_1', '15_1', '15_1', '15_1', '15_2', '15_2', '15_2', '15_2', '15_2', '15_2', '15_2', '15_0', '15_0', '15_0', '15_0', '15_0', '15_0', '15_0', '15_0', '15_0', '15_0', '15_0', '15_0', '15_0', '15_0', '15_0', '15_0', '15_0', '15_0', '15_0', '15_0', '15_0', '15_0', '15_0', '15_0', '15_0', '15_0', '15_0', '15_0', '15_0', '15_0', '15_1', '15_1', '15_1', '15_1', '15_1', '15_1', '15_1', '15_1', '15_1']\n",
      "Predicted labels:\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "--------------------------------------------------------------------------------\n",
      "Ground truth labels:\n",
      "['30_0', '30_0', '30_0', '30_0', '30_0', '30_0', '30_0', '30_0', '30_0', '30_0', '30_0', '30_0', '30_0', '30_0', '30_0', '30_0', '30_0', '30_0', '30_0', '30_0', '30_0', '30_1', '30_1', '30_1', '30_1', '30_1', '30_1', '30_1', '30_1', '30_1', '30_1', '30_1', '30_1', '30_1', '30_1', '30_1', '30_1', '30_1', '30_1', '30_1', '30_1', '30_1', '30_1', '30_0', '30_0', '30_0', '30_0', '30_0', '30_0', '30_0', '30_0', '30_0', '30_0', '30_0', '30_0', '30_0', '30_0', '30_0', '30_0', '30_0', '30_0', '30_0', '30_0', '30_0', '30_1', '30_1', '30_1', '30_1', '30_1', '30_1', '30_1', '30_1', '30_1', '30_1', '30_1', '30_1', '30_1', '30_0', '30_0', '30_0', '30_0', '30_0', '30_0', '30_0', '30_0', '30_0', '30_0', '30_0', '30_1']\n",
      "Predicted labels:\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2]\n",
      "--------------------------------------------------------------------------------\n",
      "Ground truth labels:\n",
      "['52_0', '52_0', '52_0', '52_0', '52_0', '52_0', '52_0', '52_0', '52_0', '52_0', '52_0', '52_0', '52_0', '52_0', '52_0', '52_0', '52_2', '52_2', '52_2', '52_2', '52_2', '52_2', '52_2', '52_2', '52_2', '52_2', '52_2', '52_2', '52_2', '52_2', '52_2', '52_2', '52_2', '52_2', '52_2', '52_2', '52_2', '52_2', '52_2', '52_2', '52_2', '52_2', '52_0', '52_0', '52_0', '52_0', '52_0', '52_0', '52_0', '52_0', '52_0', '52_2', '52_2', '52_2', '52_2', '52_2', '52_2', '52_2', '52_2', '52_2', '52_2', '52_2', '52_2', '52_2', '52_2', '52_1', '52_1', '52_1', '52_1', '52_1', '52_1', '52_1', '52_1', '52_1', '52_1', '52_1', '52_1', '52_1', '52_1', '52_1', '52_1', '52_1', '52_1', '52_1', '52_1', '52_1', '52_1', '52_1', '52_1', '52_1', '52_1', '52_1', '52_1', '52_1']\n",
      "Predicted labels:\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "--------------------------------------------------------------------------------\n",
      "Ground truth labels:\n",
      "['71_0', '71_0', '71_0', '71_0', '71_0', '71_0', '71_0', '71_0', '71_0', '71_0', '71_0', '71_0', '71_0', '71_0', '71_0', '71_2', '71_2', '71_2', '71_2', '71_2', '71_2', '71_2', '71_2', '71_2', '71_2', '71_2', '71_1', '71_1', '71_1', '71_1', '71_1', '71_1', '71_1', '71_1', '71_1', '71_0', '71_0', '71_0', '71_0', '71_0', '71_0', '71_0', '71_0', '71_0', '71_0', '71_0', '71_0', '71_0', '71_0', '71_0', '71_0', '71_0', '71_0', '71_0', '71_0', '71_0', '71_0', '71_0', '71_0', '71_1', '71_1', '71_1', '71_1', '71_1', '71_1', '71_1', '71_0', '71_0', '71_0', '71_0', '71_0', '71_0', '71_1', '71_1', '71_1', '71_1', '71_1', '71_1', '71_1', '71_1', '71_1', '71_1', '71_2', '71_2', '71_2', '71_2', '71_2', '71_2', '71_1', '71_1', '71_1', '71_1', '71_1', '71_1']\n",
      "Predicted labels:\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2]\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground truth labels:\n",
      "['75_0', '75_0', '75_0', '75_0', '75_0', '75_0', '75_0', '75_0', '75_2', '75_2', '75_2', '75_2', '75_2', '75_2', '75_2', '75_2', '75_2', '75_2', '75_0', '75_0', '75_0', '75_0', '75_0', '75_0', '75_0', '75_0', '75_0', '75_0', '75_0', '75_0', '75_0', '75_0', '75_0', '75_0', '75_0', '75_0', '75_0', '75_0', '75_0', '75_0', '75_0', '75_0', '75_0', '75_0', '75_0', '75_0', '75_0', '75_0', '75_0', '75_0', '75_0', '75_0', '75_0', '75_0', '75_3', '75_3', '75_3', '75_3', '75_3', '75_3', '75_3', '75_3', '75_4', '75_4', '75_4', '75_4', '75_4', '75_4', '75_4', '75_4', '75_2', '75_2', '75_2', '75_2', '75_2', '75_4', '75_4', '75_4', '75_4', '75_4', '75_4', '75_4', '75_4', '75_4', '75_4', '75_4', '75_4', '75_4', '75_3', '75_3', '75_3', '75_3', '75_3', '75_1', '75_1', '75_1', '75_1', '75_1', '75_1', '75_1', '75_1', '75_2', '75_2', '75_2']\n",
      "Predicted labels:\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 4, 4, 4, 4, 4, 4, 4, 4, 1, 1, 1]\n",
      "--------------------------------------------------------------------------------\n",
      "Ground truth labels:\n",
      "['80_0', '80_0', '80_0', '80_0', '80_0', '80_0', '80_0', '80_0', '80_0', '80_0', '80_0', '80_0', '80_0', '80_3', '80_3', '80_3', '80_3', '80_3', '80_3', '80_3', '80_3', '80_3', '80_3', '80_5', '80_5', '80_5', '80_5', '80_5', '80_5', '80_5', '80_5', '80_5', '80_5', '80_5', '80_5', '80_5', '80_4', '80_4', '80_4', '80_4', '80_4', '80_4', '80_4', '80_4', '80_0', '80_0', '80_0', '80_0', '80_0', '80_0', '80_0', '80_0', '80_0', '80_0', '80_0', '80_0', '80_3', '80_3', '80_3', '80_3', '80_3', '80_3', '80_3', '80_3', '80_3', '80_3', '80_3', '80_3', '80_3', '80_3', '80_3', '80_3', '80_4', '80_4', '80_4', '80_4', '80_4', '80_4', '80_4', '80_4', '80_4', '80_4', '80_4', '80_4', '80_4', '80_4']\n",
      "Predicted labels:\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "--------------------------------------------------------------------------------\n",
      "Ground truth labels:\n",
      "['140_0', '140_0', '140_0', '140_0', '140_0', '140_0', '140_0', '140_0', '140_0', '140_0', '140_0', '140_0', '140_0', '140_0', '140_0', '140_0', '140_0', '140_0', '140_1', '140_1', '140_1', '140_1', '140_1', '140_1', '140_1', '140_1', '140_1', '140_1', '140_1', '140_1', '140_1', '140_1', '140_1', '140_1', '140_1', '140_4', '140_4', '140_4', '140_4', '140_4', '140_4', '140_4', '140_4', '140_4', '140_4', '140_4', '140_4', '140_4', '140_4', '140_4', '140_4', '140_4', '140_4', '140_4', '140_4', '140_4', '140_4', '140_4', '140_2', '140_2', '140_2', '140_2', '140_2', '140_5', '140_5', '140_5', '140_5', '140_5', '140_5', '140_5', '140_5', '140_5', '140_0', '140_0', '140_0', '140_0', '140_0', '140_0', '140_0', '140_0', '140_0', '140_0', '140_0', '140_0', '140_4', '140_4', '140_4', '140_4', '140_4', '140_4', '140_4', '140_4', '140_4', '140_4', '140_4', '140_4']\n",
      "Predicted labels:\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "--------------------------------------------------------------------------------\n",
      "Ground truth labels:\n",
      "['146_0', '146_0', '146_0', '146_0', '146_0', '146_0', '146_0', '146_0', '146_0', '146_1', '146_1', '146_1', '146_1', '146_1', '146_1', '146_1', '146_1', '146_1', '146_1', '146_1', '146_1', '146_1', '146_1', '146_1', '146_1', '146_1', '146_1', '146_1', '146_1', '146_1', '146_1', '146_1', '146_1', '146_1', '146_1', '146_1', '146_1', '146_1', '146_1', '146_1', '146_1', '146_1', '146_1', '146_1', '146_1', '146_1', '146_1', '146_1', '146_1', '146_1', '146_1', '146_1', '146_1', '146_1', '146_1', '146_0', '146_0', '146_0', '146_0', '146_0', '146_0', '146_0', '146_0', '146_1', '146_1', '146_1', '146_1', '146_1', '146_1', '146_1', '146_1', '146_1', '146_1', '146_1', '146_1', '146_1', '146_1', '146_1', '146_0', '146_0', '146_0', '146_0', '146_0', '146_0', '146_0', '146_0', '146_0', '146_0', '146_0', '146_0', '146_1', '146_1', '146_1', '146_1', '146_1', '146_1', '146_1', '146_1', '146_1', '146_1', '146_1']\n",
      "Predicted labels:\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "--------------------------------------------------------------------------------\n",
      "Ground truth labels:\n",
      "['152_0', '152_0', '152_0', '152_0', '152_0', '152_0', '152_0', '152_0', '152_0', '152_0', '152_1', '152_1', '152_1', '152_1', '152_1', '152_1', '152_1', '152_1', '152_1', '152_1', '152_4', '152_4', '152_4', '152_4', '152_4', '152_4', '152_4', '152_4', '152_4', '152_4', '152_4', '152_4', '152_4', '152_4', '152_4', '152_4', '152_2', '152_2', '152_2', '152_2', '152_2', '152_2', '152_2', '152_2', '152_2', '152_1', '152_1', '152_1', '152_1', '152_1', '152_1', '152_1', '152_1', '152_1', '152_1', '152_1', '152_1', '152_1', '152_1', '152_1', '152_1', '152_1', '152_1', '152_0', '152_0', '152_0', '152_0', '152_0', '152_0', '152_0', '152_0', '152_0', '152_0', '152_0', '152_0', '152_0', '152_0', '152_0', '152_0', '152_2', '152_2', '152_2', '152_2', '152_2', '152_2', '152_2', '152_2', '152_2', '152_2', '152_2', '152_0', '152_0', '152_0', '152_0', '152_0', '152_0', '152_0', '152_0', '152_2', '152_2', '152_2', '152_2']\n",
      "Predicted labels:\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 4, 4, 4, 4, 4, 4, 4, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 4, 4]\n",
      "--------------------------------------------------------------------------------\n",
      "Ground truth labels:\n",
      "['175_0', '175_0', '175_0', '175_0', '175_0', '175_0', '175_0', '175_2', '175_2', '175_2', '175_2', '175_2', '175_2', '175_2', '175_2', '175_2', '175_2', '175_1', '175_1', '175_1', '175_1', '175_1', '175_1', '175_1', '175_1', '175_1', '175_1', '175_1', '175_1', '175_1', '175_1', '175_1', '175_1', '175_2', '175_2', '175_2', '175_2', '175_2', '175_2', '175_2', '175_2', '175_2', '175_2', '175_2', '175_2', '175_2', '175_2', '175_2', '175_2', '175_2', '175_2', '175_2', '175_2', '175_2', '175_2', '175_2', '175_2', '175_2', '175_2', '175_2', '175_2', '175_1', '175_1', '175_1', '175_1', '175_1', '175_1', '175_1', '175_2', '175_2', '175_2', '175_2', '175_2', '175_2', '175_2', '175_2', '175_2', '175_2', '175_2', '175_2', '175_0', '175_0', '175_0', '175_0', '175_0', '175_0', '175_0', '175_0', '175_0', '175_0', '175_1', '175_1', '175_1', '175_1']\n",
      "Predicted labels:\n",
      "[0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2]\n",
      "--------------------------------------------------------------------------------\n",
      "Ground truth labels:\n",
      "['204_0', '204_0', '204_0', '204_0', '204_0', '204_0', '204_0', '204_0', '204_0', '204_0', '204_0', '204_0', '204_0', '204_3', '204_3', '204_3', '204_3', '204_3', '204_3', '204_3', '204_3', '204_3', '204_3', '204_3', '204_3', '204_1', '204_1', '204_1', '204_1', '204_1', '204_1', '204_1', '204_1', '204_1', '204_1', '204_1', '204_1', '204_3', '204_3', '204_3', '204_3', '204_3', '204_3', '204_1', '204_1', '204_1', '204_1', '204_1', '204_1', '204_1', '204_1', '204_1', '204_1', '204_0', '204_0', '204_0', '204_0', '204_0', '204_3', '204_3', '204_3', '204_3', '204_3', '204_3', '204_3', '204_3', '204_3', '204_3', '204_3', '204_3', '204_3', '204_3', '204_3', '204_2', '204_2', '204_2', '204_2', '204_2', '204_2', '204_2', '204_2', '204_2', '204_2', '204_2', '204_0', '204_0', '204_0', '204_0', '204_0', '204_0', '204_0', '204_0', '204_0', '204_0']\n",
      "Predicted labels:\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground truth labels:\n",
      "['315_0', '315_0', '315_0', '315_0', '315_0', '315_0', '315_0', '315_0', '315_0', '315_0', '315_0', '315_0', '315_2', '315_2', '315_2', '315_2', '315_2', '315_2', '315_2', '315_2', '315_2', '315_2', '315_2', '315_2', '315_2', '315_2', '315_2', '315_2', '315_2', '315_2', '315_2', '315_2', '315_2', '315_2', '315_2', '315_1', '315_1', '315_1', '315_1', '315_1', '315_1', '315_1', '315_1', '315_1', '315_1', '315_1', '315_1', '315_1', '315_1', '315_1', '315_1', '315_2', '315_2', '315_2', '315_2', '315_2', '315_2', '315_2', '315_1', '315_1', '315_1', '315_1', '315_1', '315_1', '315_1', '315_1', '315_1', '315_1', '315_1', '315_1', '315_4', '315_4', '315_4', '315_4', '315_4', '315_4', '315_4', '315_4', '315_4', '315_2', '315_2', '315_2', '315_2', '315_2', '315_2', '315_1', '315_1', '315_1', '315_1', '315_1', '315_1', '315_1', '315_1', '315_1', '315_5', '315_5', '315_5', '315_5']\n",
      "Predicted labels:\n",
      "[0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 5, 5, 5, 5]\n",
      "--------------------------------------------------------------------------------\n",
      "Ground truth labels:\n",
      "['333_0', '333_0', '333_0', '333_0', '333_0', '333_0', '333_0', '333_0', '333_1', '333_1', '333_1', '333_1', '333_1', '333_1', '333_1', '333_1', '333_1', '333_1', '333_1', '333_1', '333_1', '333_1', '333_1', '333_1', '333_1', '333_1', '333_1', '333_1', '333_1', '333_1', '333_1', '333_1', '333_1', '333_1', '333_1', '333_1', '333_1', '333_1', '333_1', '333_1', '333_1', '333_1', '333_1', '333_1', '333_0', '333_0', '333_0', '333_0', '333_0', '333_0', '333_0', '333_0', '333_0', '333_0', '333_0', '333_0', '333_0', '333_0', '333_0', '333_1', '333_1', '333_1', '333_1', '333_1', '333_1', '333_1', '333_1', '333_1', '333_1', '333_1', '333_1', '333_0', '333_0', '333_0', '333_0', '333_0', '333_0', '333_0', '333_0', '333_0', '333_0', '333_0', '333_1', '333_1', '333_1', '333_1', '333_1', '333_1', '333_1', '333_1']\n",
      "Predicted labels:\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "--------------------------------------------------------------------------------\n",
      "Ground truth labels:\n",
      "['347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0', '347_0']\n",
      "Predicted labels:\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "--------------------------------------------------------------------------------\n",
      "Ground truth labels:\n",
      "['361_0', '361_0', '361_0', '361_0', '361_0', '361_0', '361_0', '361_0', '361_0', '361_0', '361_1', '361_1', '361_1', '361_1', '361_1', '361_1', '361_1', '361_1', '361_1', '361_1', '361_1', '361_1', '361_0', '361_0', '361_0', '361_0', '361_0', '361_0', '361_0', '361_0', '361_0', '361_0', '361_0', '361_2', '361_2', '361_2', '361_2', '361_2', '361_2', '361_2', '361_2', '361_2', '361_2', '361_2', '361_1', '361_1', '361_1', '361_1', '361_1', '361_1', '361_1', '361_1', '361_1', '361_1', '361_1', '361_1', '361_1', '361_1', '361_2', '361_2', '361_2', '361_2', '361_2', '361_2', '361_2', '361_2', '361_2', '361_2', '361_2', '361_2', '361_2', '361_2', '361_2', '361_2', '361_2', '361_2', '361_2', '361_2', '361_2', '361_2', '361_2', '361_2', '361_2', '361_2', '361_2', '361_2', '361_2', '361_2', '361_2', '361_3', '361_3', '361_3', '361_3', '361_3', '361_3', '361_3', '361_3', '361_3', '361_3', '361_3', '361_3', '361_3', '361_3', '361_3', '361_3', '361_3', '361_1', '361_1', '361_1', '361_1', '361_1', '361_1', '361_1', '361_1', '361_1', '361_1', '361_1', '361_1', '361_1', '361_1', '361_1', '361_1', '361_1']\n",
      "Predicted labels:\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "--------------------------------------------------------------------------------\n",
      "Ground truth labels:\n",
      "['374_0', '374_0', '374_0', '374_0', '374_0', '374_0', '374_0', '374_0', '374_0', '374_0', '374_0', '374_0', '374_0', '374_0', '374_0', '374_1', '374_1', '374_1', '374_1', '374_1', '374_1', '374_1', '374_1', '374_1', '374_1', '374_1', '374_1', '374_1', '374_1', '374_1', '374_1', '374_1', '374_1', '374_1', '374_1', '374_1', '374_1', '374_0', '374_0', '374_0', '374_0', '374_0', '374_0', '374_0', '374_0', '374_0', '374_1', '374_1', '374_1', '374_1', '374_1', '374_1', '374_1', '374_1', '374_1', '374_1', '374_1', '374_1', '374_1', '374_1', '374_1', '374_1', '374_1', '374_0', '374_0', '374_0', '374_0', '374_0', '374_0', '374_0', '374_0', '374_0', '374_0', '374_0', '374_0', '374_0', '374_0', '374_1', '374_1', '374_1', '374_1', '374_0', '374_0', '374_0', '374_0', '374_0', '374_0', '374_0', '374_0', '374_0', '374_0', '374_0', '374_0', '374_0', '374_0', '374_0', '374_0', '374_0', '374_0', '374_0', '374_0', '374_0', '374_0', '374_0', '374_1', '374_1', '374_1', '374_1', '374_1', '374_1', '374_1', '374_1', '374_1', '374_1', '374_1', '374_1', '374_0', '374_0', '374_0']\n",
      "Predicted labels:\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]\n",
      "--------------------------------------------------------------------------------\n",
      "Ground truth labels:\n",
      "['405_0', '405_0', '405_0', '405_0', '405_0', '405_0', '405_0', '405_1', '405_1', '405_1', '405_1', '405_1', '405_1', '405_1', '405_1', '405_2', '405_2', '405_2', '405_2', '405_2', '405_2', '405_2', '405_2', '405_0', '405_0', '405_0', '405_0', '405_0', '405_0', '405_0', '405_0', '405_0', '405_0', '405_0', '405_0', '405_0', '405_0', '405_0', '405_0', '405_1', '405_1', '405_1', '405_1', '405_1', '405_1', '405_1', '405_1', '405_1', '405_1', '405_1', '405_1', '405_0', '405_0', '405_0', '405_0', '405_0', '405_0', '405_0', '405_0', '405_0', '405_0', '405_0', '405_0', '405_0', '405_2', '405_2', '405_2', '405_2', '405_2', '405_2', '405_2', '405_0', '405_0', '405_0', '405_0', '405_0', '405_0', '405_0', '405_0', '405_0', '405_0', '405_0', '405_0', '405_0', '405_0', '405_0', '405_0', '405_0', '405_0', '405_0', '405_0', '405_0', '405_0', '405_0', '405_0', '405_0', '405_0', '405_0', '405_0', '405_0', '405_0', '405_0', '405_0', '405_1', '405_1', '405_1', '405_1']\n",
      "Predicted labels:\n",
      "[0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1]\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground truth labels:\n",
      "['419_0', '419_0', '419_0', '419_0', '419_0', '419_0', '419_0', '419_0', '419_0', '419_0', '419_1', '419_1', '419_1', '419_1', '419_1', '419_1', '419_1', '419_1', '419_1', '419_1', '419_1', '419_4', '419_4', '419_4', '419_4', '419_4', '419_4', '419_4', '419_4', '419_4', '419_4', '419_4', '419_3', '419_3', '419_3', '419_3', '419_3', '419_3', '419_3', '419_3', '419_3', '419_3', '419_1', '419_1', '419_1', '419_1', '419_1', '419_1', '419_1', '419_1', '419_1', '419_1', '419_2', '419_2', '419_2', '419_2', '419_2', '419_2', '419_2', '419_0', '419_0', '419_0', '419_0', '419_0', '419_1', '419_1', '419_1', '419_1', '419_1', '419_1', '419_1', '419_1', '419_1', '419_1', '419_6', '419_6', '419_6', '419_6', '419_6', '419_6', '419_6', '419_6', '419_6', '419_6', '419_6', '419_6', '419_6', '419_6', '419_4', '419_4', '419_4', '419_4', '419_4', '419_4']\n",
      "Predicted labels:\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 4, 4, 4, 4, 4, 4, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 2, 2, 2, 2, 2, 2]\n",
      "--------------------------------------------------------------------------------\n",
      "Ground truth labels:\n",
      "['430_0', '430_0', '430_0', '430_0', '430_0', '430_0', '430_0', '430_0', '430_0', '430_0', '430_0', '430_0', '430_0', '430_0', '430_0', '430_0', '430_0', '430_0', '430_0', '430_0', '430_0', '430_0', '430_0', '430_0', '430_0', '430_0', '430_0', '430_0', '430_0', '430_0', '430_0', '430_0', '430_0', '430_0', '430_0', '430_0', '430_0', '430_0', '430_0', '430_0', '430_0', '430_0', '430_0', '430_0', '430_0', '430_0', '430_0', '430_0', '430_0', '430_0', '430_0', '430_0', '430_0', '430_0', '430_0', '430_0', '430_0', '430_0', '430_0', '430_0', '430_0', '430_0', '430_0', '430_0', '430_0', '430_0', '430_0', '430_0', '430_0', '430_0', '430_0', '430_0', '430_0', '430_0', '430_0', '430_0', '430_0', '430_0', '430_0', '430_0', '430_0', '430_0', '430_0', '430_0', '430_0', '430_0', '430_0', '430_0', '430_0', '430_0', '430_0', '430_0', '430_0', '430_0', '430_0', '430_0', '430_0', '430_0', '430_0', '430_0', '430_0', '430_0', '430_0', '430_0', '430_0', '430_0', '430_0']\n",
      "Predicted labels:\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "--------------------------------------------------------------------------------\n",
      "Ground truth labels:\n",
      "['439_0', '439_0', '439_0', '439_0', '439_0', '439_0', '439_0', '439_0', '439_0', '439_2', '439_2', '439_2', '439_2', '439_2', '439_2', '439_2', '439_2', '439_2', '439_2', '439_4', '439_4', '439_4', '439_4', '439_4', '439_4', '439_4', '439_4', '439_4', '439_4', '439_4', '439_2', '439_2', '439_2', '439_2', '439_2', '439_3', '439_3', '439_3', '439_3', '439_3', '439_3', '439_3', '439_3', '439_3', '439_4', '439_4', '439_4', '439_4', '439_4', '439_4', '439_4', '439_4', '439_1', '439_1', '439_1', '439_1', '439_1', '439_1', '439_1', '439_1', '439_1', '439_1', '439_1', '439_1', '439_1', '439_1', '439_3', '439_3', '439_3', '439_3', '439_3', '439_3', '439_3', '439_3', '439_3', '439_3', '439_2', '439_2', '439_2', '439_2', '439_2', '439_1', '439_1', '439_1', '439_1', '439_1', '439_1', '439_1', '439_1', '439_1', '439_4', '439_4', '439_4', '439_4', '439_4', '439_4', '439_4', '439_4', '439_4']\n",
      "Predicted labels:\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "--------------------------------------------------------------------------------\n",
      "Ground truth labels:\n",
      "['441_0', '441_0', '441_0', '441_0', '441_0', '441_0', '441_0', '441_0', '441_0', '441_0', '441_0', '441_0', '441_0', '441_0', '441_0', '441_0', '441_0', '441_0', '441_0', '441_0', '441_1', '441_1', '441_1', '441_1', '441_1', '441_1', '441_1', '441_1', '441_1', '441_1', '441_1', '441_1', '441_1', '441_1', '441_1', '441_1', '441_1', '441_1', '441_1', '441_1', '441_1', '441_1', '441_1', '441_1', '441_1', '441_1', '441_1', '441_1', '441_1', '441_0', '441_0', '441_0', '441_0', '441_0', '441_0', '441_0', '441_0', '441_0', '441_0', '441_0', '441_0', '441_0', '441_0', '441_0', '441_0', '441_0', '441_1', '441_1', '441_1', '441_1', '441_1', '441_1', '441_1', '441_1', '441_1', '441_1', '441_1', '441_1', '441_1', '441_1', '441_1', '441_1', '441_1', '441_1', '441_1', '441_1', '441_1', '441_1', '441_1', '441_1', '441_1', '441_1', '441_1', '441_1', '441_0', '441_0', '441_0', '441_0', '441_0', '441_0', '441_0', '441_0', '441_0', '441_0', '441_0', '441_0', '441_0', '441_1', '441_1', '441_1', '441_1', '441_1', '441_1', '441_1', '441_1', '441_0', '441_0', '441_0', '441_0', '441_0', '441_0', '441_0', '441_0', '441_0']\n",
      "Predicted labels:\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "--------------------------------------------------------------------------------\n",
      "Ground truth labels:\n",
      "['442_0', '442_0', '442_0', '442_0', '442_0', '442_0', '442_0', '442_0', '442_0', '442_0', '442_0', '442_0', '442_0', '442_0', '442_0', '442_0', '442_0', '442_0', '442_0', '442_0', '442_0', '442_0', '442_0', '442_0', '442_0', '442_0', '442_0', '442_0', '442_0', '442_0', '442_0', '442_0', '442_0', '442_0', '442_0', '442_0', '442_0', '442_0', '442_0', '442_0', '442_0', '442_0', '442_0', '442_0', '442_0', '442_0', '442_0', '442_0', '442_0', '442_0', '442_0', '442_0', '442_0', '442_0', '442_0', '442_0', '442_0', '442_0', '442_0', '442_0', '442_0', '442_0', '442_0', '442_0', '442_0', '442_0', '442_0', '442_0', '442_0', '442_0', '442_0', '442_0', '442_0', '442_0', '442_0', '442_0', '442_0', '442_0', '442_0', '442_0', '442_0', '442_0', '442_0', '442_0', '442_0']\n",
      "Predicted labels:\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "--------------------------------------------------------------------------------\n",
      "Ground truth labels:\n",
      "['459_0', '459_0', '459_0', '459_0', '459_0', '459_0', '459_0', '459_0', '459_0', '459_0', '459_0', '459_0', '459_0', '459_0', '459_0', '459_0', '459_0', '459_0', '459_0', '459_0', '459_0', '459_0', '459_0', '459_0', '459_0', '459_0', '459_0', '459_0', '459_0', '459_1', '459_1', '459_1', '459_1', '459_1', '459_1', '459_1', '459_1', '459_1', '459_1', '459_1', '459_0', '459_0', '459_0', '459_0', '459_0', '459_0', '459_0', '459_0', '459_0', '459_0', '459_0', '459_0', '459_0', '459_0', '459_0', '459_0', '459_0', '459_0', '459_0', '459_0', '459_0', '459_0', '459_0', '459_0', '459_0', '459_0', '459_0', '459_0', '459_0', '459_0', '459_0', '459_0', '459_0', '459_0', '459_0', '459_0', '459_0', '459_0', '459_0', '459_0', '459_0', '459_0', '459_0', '459_0', '459_0', '459_0', '459_0', '459_0', '459_0', '459_0', '459_0', '459_0', '459_0', '459_0', '459_0', '459_0', '459_0', '459_0', '459_0', '459_0', '459_0', '459_0', '459_0', '459_0', '459_0', '459_1', '459_1', '459_1', '459_1', '459_1', '459_1', '459_1', '459_1', '459_1', '459_1', '459_1', '459_1', '459_1', '459_1', '459_1', '459_1', '459_1', '459_1', '459_1', '459_1']\n",
      "Predicted labels:\n",
      "[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground truth labels:\n",
      "['491_0', '491_0', '491_0', '491_0', '491_0', '491_0', '491_0', '491_0', '491_0', '491_0', '491_0', '491_0', '491_0', '491_0', '491_3', '491_3', '491_3', '491_3', '491_3', '491_3', '491_3', '491_3', '491_3', '491_3', '491_3', '491_3', '491_3', '491_3', '491_3', '491_0', '491_0', '491_0', '491_0', '491_0', '491_0', '491_0', '491_0', '491_0', '491_0', '491_0', '491_0', '491_0', '491_0', '491_0', '491_0', '491_0', '491_0', '491_0', '491_0', '491_0', '491_0', '491_0', '491_1', '491_1', '491_1', '491_1', '491_1', '491_1', '491_1', '491_1', '491_1', '491_1', '491_1', '491_1', '491_1', '491_0', '491_0', '491_0', '491_0', '491_0', '491_0', '491_0', '491_1', '491_1', '491_1', '491_1', '491_1', '491_1', '491_1', '491_1', '491_3', '491_3', '491_3', '491_3', '491_3', '491_3', '491_3', '491_3', '491_3', '491_3', '491_3', '491_3', '491_1', '491_1', '491_1', '491_1', '491_1', '491_1', '491_1', '491_1', '491_1']\n",
      "Predicted labels:\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "--------------------------------------------------------------------------------\n",
      "Ground truth labels:\n",
      "['494_0', '494_0', '494_0', '494_0', '494_0', '494_0', '494_0', '494_0', '494_1', '494_1', '494_1', '494_1', '494_1', '494_1', '494_1', '494_1', '494_0', '494_0', '494_0', '494_0', '494_0', '494_0', '494_0', '494_0', '494_0', '494_0', '494_2', '494_2', '494_2', '494_2', '494_1', '494_1', '494_1', '494_1', '494_1', '494_1', '494_1', '494_1', '494_1', '494_1', '494_1', '494_1', '494_1', '494_1', '494_1', '494_1', '494_1', '494_1', '494_1', '494_1', '494_1', '494_1', '494_1', '494_1', '494_1', '494_2', '494_2', '494_2', '494_2', '494_2', '494_2', '494_2', '494_2', '494_2', '494_2', '494_0', '494_0', '494_0', '494_0', '494_0', '494_0', '494_0', '494_0', '494_1', '494_1', '494_1', '494_1', '494_1', '494_1', '494_1', '494_1', '494_1', '494_1', '494_1', '494_1', '494_1', '494_1', '494_0', '494_0']\n",
      "Predicted labels:\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]\n",
      "--------------------------------------------------------------------------------\n",
      "Finished diarization experiment\n",
      "Config:\n",
      "  sigma_alpha: 1.0\n",
      "  sigma_beta: 1.0\n",
      "  crp_alpha: 1.0\n",
      "  learning rate: 0.001\n",
      "  regularization: 1e-05\n",
      "  batch size: 10\n",
      "\n",
      "Performance:\n",
      "  averaged accuracy: 0.995235\n",
      "  accuracy numbers for all testing sequences:\n",
      "    1.000000\n",
      "    0.988764\n",
      "    0.989362\n",
      "    1.000000\n",
      "    1.000000\n",
      "    1.000000\n",
      "    0.989583\n",
      "    1.000000\n",
      "    0.990196\n",
      "    0.989362\n",
      "    0.989362\n",
      "    0.989796\n",
      "    0.988889\n",
      "    1.000000\n",
      "    0.991870\n",
      "    0.991597\n",
      "    1.000000\n",
      "    1.000000\n",
      "    1.000000\n",
      "    1.000000\n",
      "    1.000000\n",
      "    1.000000\n",
      "    0.992000\n",
      "    0.990099\n",
      "    1.000000\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
