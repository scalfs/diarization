{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/jovyan/.cache/torch/hub/pyannote_pyannote-audio_master\n",
      "/opt/conda/lib/python3.9/site-packages/pyannote/audio/embedding/approaches/arcface_loss.py:170: FutureWarning: The 's' parameter is deprecated in favor of 'scale', and will be removed in a future release\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding has dimension 512.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from pyannote.database import get_protocol, FileFinder\n",
    "\n",
    "emb = torch.hub.load('pyannote/pyannote-audio', 'emb')\n",
    "print(f'Embedding has dimension {emb.dimension:d}.')\n",
    "\n",
    "preprocessors = {'audio': FileFinder()}\n",
    "protocol = get_protocol('VOXCON.SpeakerDiarization.Sample', preprocessors=preprocessors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abjxc 03:09:14\n",
      "abjxc 03:09:16\n",
      "Embeddings were extracted every 1000ms on 4000ms-long windows.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# embs = []\n",
    "\n",
    "# for file in protocol.test():\n",
    "#     embeddings = emb(file)\n",
    "#     embs.append(embeddings)\n",
    "    \n",
    "#     uri = file['uri']\n",
    "#     print(uri, time.strftime(\"%H:%M:%S\"))\n",
    "\n",
    "    \n",
    "test_file = next(protocol.train())\n",
    "uri = test_file['uri']\n",
    "print(uri, time.strftime(\"%H:%M:%S\"))\n",
    "embeddings = emb(test_file)\n",
    "print(uri, time.strftime(\"%H:%M:%S\"))\n",
    "\n",
    "chunks = embeddings.sliding_window\n",
    "print(f'Embeddings were extracted every {1000 * chunks.step:g}ms on {1000 * chunks.duration:g}ms-long windows.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68.376"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import librosa\n",
    "audio_path = test_file['audio'].as_posix()\n",
    "utter, sr = librosa.core.load(audio_path, sr=16000) \n",
    "librosa.get_duration(utter, sr=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from IPython.display import display, clear_output\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "X, Y = [], []\n",
    "\n",
    "fileIndex = 7\n",
    "\n",
    "embeddings = embs[fileIndex]\n",
    "length = len(embeddings)\n",
    "rttm = list(protocol.test())[fileIndex][\"annotation\"]\n",
    "\n",
    "for id, (window, embedding) in enumerate(embeddings):\n",
    "    # average speech turn embedding\n",
    "    X.append(np.nanmean(embedding, axis=0))\n",
    "\n",
    "    # keep track of speaker label (for later scatter plot)\n",
    "    y = rttm.argmax(window)\n",
    "    Y.append(y)\n",
    "    clear_output(wait=True)\n",
    "    display(f'{id+1} {100*(id+1)/length:g}%')\n",
    "\n",
    "X = np.vstack(X)\n",
    "_, y_true = np.unique(Y, return_inverse=True)\n",
    "\n",
    "tsne = TSNE(n_components=2, metric=\"cosine\")\n",
    "X_2d = tsne.fit_transform(X)\n",
    "\n",
    "# plot \n",
    "fig, ax = plt.subplots()\n",
    "fig.set_figheight(5)\n",
    "fig.set_figwidth(5)\n",
    "plt.clf()\n",
    "plt.scatter(*X_2d.T, c=y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for resource in protocol.test():\n",
    "#     print(resource[\"audio\"])\n",
    "#     print(resource[\"uri\"])\n",
    "\n",
    "# test_file = next(protocol.test())\n",
    "# test_file[\"audio\"]\n",
    "\n",
    "###########################################\n",
    "\n",
    "# sw = SlidingWindow(duration=4, step=1, start=0.0, end=len(embeddings))\n",
    "\n",
    "# for segment in sw:\n",
    "#     # \"strict\" only keeps embedding strictly included in segment\n",
    "#     x = embeddings.crop(segment, mode='strict')\n",
    "\n",
    "############################################\n",
    "\n",
    "# from pyannote.core import Segment\n",
    "# import numpy as np\n",
    "\n",
    "# for id, (window, emb) in enumerate(embeddings):\n",
    "#     print(window, emb)\n",
    "#     assert isinstance(window, Segment)\n",
    "#     assert isinstance(emb, np.ndarray)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
