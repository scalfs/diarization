{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import torch\n",
    "from pyannote.database import get_protocol, FileFinder\n",
    "\n",
    "emb = torch.hub.load('pyannote/pyannote-audio', 'emb')\n",
    "print(f'Embedding has dimension {emb.dimension:d}.')\n",
    "\n",
    "preprocessors = {'audio': FileFinder()}\n",
    "protocol = get_protocol('VOXCON.SpeakerDiarization.Sample', preprocessors=preprocessors)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "test_file = next(protocol.test())\n",
    "\n",
    "embeddings = emb(test_file)\n",
    "\n",
    "chunks = embeddings.sliding_window\n",
    "print(f'Embeddings were extracted every {1000 * chunks.step:g}ms on {1000 * chunks.duration:g}ms-long windows.')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "test_file = (next(protocol.test()))\n",
    "protocol.test()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "X, Y = [], []\n",
    "length = len(embeddings)\n",
    "\n",
    "for id, (window, embedding) in enumerate(embeddings):\n",
    "    # average speech turn embedding\n",
    "    X.append(np.nanmean(embedding, axis=0))\n",
    "\n",
    "    # keep track of speaker label (for later scatter plot)\n",
    "    y = test_file['annotation'].argmax(window)\n",
    "    Y.append(y)\n",
    "    clear_output(wait=True)\n",
    "    display(f'{id+1} {100*(id+1)/length:g}%')\n",
    "\n",
    "X = np.vstack(X)\n",
    "_, y_true = np.unique(Y, return_inverse=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "tsne = TSNE(n_components=2, metric=\"cosine\")\n",
    "X_2d = tsne.fit_transform(X)\n",
    "\n",
    "# plot \n",
    "fig, ax = plt.subplots()\n",
    "fig.set_figheight(5)\n",
    "fig.set_figwidth(5)\n",
    "plt.clf()\n",
    "plt.scatter(*X_2d.T, c=y_true)\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# for resource in protocol.test():\n",
    "#     print(resource[\"audio\"])\n",
    "#     print(resource[\"uri\"])\n",
    "\n",
    "# test_file = next(protocol.test())\n",
    "# test_file[\"audio\"]\n",
    "\n",
    "###########################################\n",
    "\n",
    "# sw = SlidingWindow(duration=4, step=1, start=0.0, end=len(embeddings))\n",
    "\n",
    "# for segment in sw:\n",
    "#     # \"strict\" only keeps embedding strictly included in segment\n",
    "#     x = embeddings.crop(segment, mode='strict')\n",
    "\n",
    "############################################\n",
    "\n",
    "# from pyannote.core import Segment\n",
    "# import numpy as np\n",
    "\n",
    "# for id, (window, emb) in enumerate(embeddings):\n",
    "#     print(window, emb)\n",
    "#     assert isinstance(window, Segment)\n",
    "#     assert isinstance(emb, np.ndarray)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}